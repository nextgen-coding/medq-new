# üîÑ Migration Guide: 50‚Üí5 Questions Per Call

## üìã Pre-Deployment Checklist

- [ ] Read `AI_CONFIG_UPDATE_SUMMARY.md`
- [ ] Review `AI_5Q_PER_CALL_OPTIMIZATION.md`
- [ ] Test in development environment
- [ ] Verify Azure OpenAI rate limits (7000 RPM confirmed)
- [ ] Backup current configuration
- [ ] Plan deployment window (low-traffic period recommended)

---

## üöÄ Deployment Steps

### **Step 1: Verify Current Configuration**

```bash
# Check current settings in logs
grep "BATCH_SIZE" logs/app.log
grep "CONCURRENCY" logs/app.log

# Expected output (old):
# [AI] Configured: BATCH_SIZE=50, CONCURRENCY=50
```

### **Step 2: Deploy New Configuration**

The configuration is already updated in `route.ts`:
```typescript
const BATCH_SIZE = 5;       // ‚úÖ Updated
const CONCURRENCY = 100;    // ‚úÖ Updated
```

**Deploy via:**
```bash
# Git commit and push
git add src/app/api/validation/ai-progress/route.ts
git commit -m "feat: optimize AI processing to 5 Q/call with 100 concurrency"
git push origin master

# Or if using deployment platform
# Deploy through your CI/CD pipeline
```

### **Step 3: Verify Deployment**

```bash
# Check new settings in logs
grep "Optimal Configuration" logs/app.log

# Expected output (new):
# [AI] üéØ Optimal Configuration Active:
# [AI]    üì¶ Batch Size: 5 questions per API call
# [AI]    üîÑ Concurrency: 100 parallel API calls
# [AI]    üìä Estimated RPM: 6000 ‚úÖ (limit: 7000)
```

---

## üß™ Testing Plan

### **Test 1: Small File (100 Questions)**

```bash
# Upload test file
curl -X POST /api/validation/ai-progress \
  -F "file=@test_100q.xlsx"

# Expected results:
# - Time: 2-3 seconds
# - Waves: 1
# - API calls: 20
# - Success rate: >99%
```

**Log Output to Verify:**
```
[AI] üì¶ Created 20 batches (5 questions each)
[AI] üåä Will process in 1 wave(s)
[AI] ‚úÖ Wave 1/1: All 20 calls complete in 2.3s
```

### **Test 2: Medium File (500 Questions)**

```bash
# Upload test file
curl -X POST /api/validation/ai-progress \
  -F "file=@test_500q.xlsx"

# Expected results:
# - Time: 2-3 seconds
# - Waves: 1
# - API calls: 100
# - Success rate: >99%
```

**Log Output to Verify:**
```
[AI] üì¶ Created 100 batches (5 questions each)
[AI] üåä Will process in 1 wave(s)
[AI] ‚úÖ Wave 1/1: All 100 calls complete in 2.5s
```

### **Test 3: Large File (2749 Questions)**

```bash
# Upload test file
curl -X POST /api/validation/ai-progress \
  -F "file=@test_2749q.xlsx"

# Expected results:
# - Time: 10-12 seconds
# - Waves: 6
# - API calls: 550
# - Success rate: >99%
```

**Log Output to Verify:**
```
[AI] üì¶ Created 550 batches (5 questions each)
[AI] üåä Will process in 6 wave(s)
[AI] ‚úÖ Wave 1/6: All 100 calls complete in 2.3s
[AI] ‚úÖ Wave 2/6: All 100 calls complete in 2.1s
...
[AI] ‚úÖ Wave 6/6: All 50 calls complete in 1.1s
[AI] ‚úÖ 2749 questions analyzed in 11.8s
```

---

## üìä Monitoring

### **Key Metrics to Watch**

#### **1. Processing Time**
```bash
# Monitor average processing time
grep "questions analyzed in" logs/app.log | awk '{print $NF}'

# Expected: Should decrease for files >1000 questions
```

#### **2. Error Rate**
```bash
# Monitor error rates
grep "Results:" logs/app.log

# Expected: <1% error rate
# Example: "Results: 2742 OK, 7 errors" = 0.25% error rate ‚úÖ
```

#### **3. Rate Limit Usage**
```bash
# Monitor RPM usage
grep "Estimated RPM" logs/app.log

# Expected: 6000 ‚úÖ (under 7000 limit)
# Warning: If you see 429 errors, reduce concurrency
```

#### **4. Wave Processing Time**
```bash
# Monitor wave completion times
grep "Wave.*complete in" logs/app.log

# Expected: ~2s per wave
# Warning: If >5s, investigate network/API issues
```

---

## üö® Rollback Procedure

### **Option 1: Environment Variables (Fastest)**

```bash
# Set environment variables (no deployment needed)
export AI_IMPORT_BATCH_SIZE=50
export AI_IMPORT_CONCURRENCY=50

# Restart application
pm2 restart app
# or
systemctl restart your-app
```

### **Option 2: Code Rollback**

```bash
# Revert git commit
git revert HEAD
git push origin master

# Or manually edit route.ts:
# Change line:
const BATCH_SIZE = 5;        # ‚Üí 50
const CONCURRENCY = 100;     # ‚Üí 50
```

### **Option 3: Slow Mode (Temporary Fix)**

```bash
# Enable slow mode as temporary measure
export AI_SLOW_MODE=1

# This uses: 20 batch, 30 concurrency
# Restart application
```

---

## ‚ö†Ô∏è Potential Issues & Solutions

### **Issue 1: 429 Rate Limit Errors**

**Symptom:**
```
Error: 429 Too Many Requests
[AI] ‚ùå Batch 45/100: Failed - Rate limit exceeded
```

**Solution:**
```bash
# Reduce concurrency temporarily
export AI_IMPORT_CONCURRENCY=80

# Or enable slow mode
export AI_SLOW_MODE=1

# Permanent fix: Increase Azure rate limit tier
```

### **Issue 2: Slow Wave Processing (>5s)**

**Symptom:**
```
[AI] ‚úÖ Wave 1/6: All 100 calls complete in 15.3s ‚ö†Ô∏è
```

**Possible Causes:**
- Network latency to Azure
- Azure service throttling
- Database bottleneck

**Solution:**
```bash
# Reduce concurrency for stability
export AI_IMPORT_CONCURRENCY=50

# Check Azure service health
# Check network connection
# Monitor database performance
```

### **Issue 3: High Error Rate (>5%)**

**Symptom:**
```
[AI] üìä Results: 2500 OK, 249 errors ‚ùå (9% error rate)
```

**Possible Causes:**
- Malformed questions in batch
- Azure API instability
- Token limit issues

**Solution:**
```bash
# Reduce batch size for simpler processing
export AI_IMPORT_BATCH_SIZE=3

# Enable single mode for debugging
export AI_QCM_SINGLE=1  # Process 1 at a time to isolate issue

# Check Azure API status
# Review error logs for patterns
```

### **Issue 4: Timeout Errors**

**Symptom:**
```
Error: Request timeout after 30s
```

**Solution:**
```bash
# Increase timeout in code
# Or reduce batch size
export AI_IMPORT_BATCH_SIZE=3

# Or reduce concurrency
export AI_IMPORT_CONCURRENCY=50
```

---

## üìà Performance Comparison

### **Before Deployment (Expected Old Performance)**

```bash
# Process 2749 questions
Time: ~25 seconds
Waves: 2
RPM: 3000 (43% of limit)
Error impact: Lose 50Q per failed call
```

### **After Deployment (Expected New Performance)**

```bash
# Process 2749 questions
Time: ~11 seconds ‚úÖ (2.3x faster)
Waves: 6 ‚úÖ (more granular progress)
RPM: 6000 ‚úÖ (86% of limit - optimized)
Error impact: Lose 5Q per failed call ‚úÖ (10x better)
```

---

## üéØ Success Criteria

Deployment is successful if:

- ‚úÖ Processing time for 2749Q: **10-15 seconds** (was ~25s)
- ‚úÖ Error rate: **<1%** (same as before)
- ‚úÖ Rate limit errors: **0** (no 429 errors)
- ‚úÖ Wave processing time: **~2 seconds each** (consistent)
- ‚úÖ User feedback: **Positive** (faster results)

---

## üìû Support Contacts

**Issues during migration?**

1. **Check logs**: Look for error patterns
2. **Review docs**: `AI_CONFIG_QUICK_REF.md`
3. **Rollback if needed**: Use environment variables
4. **Contact team**: Share error logs and metrics

---

## üîç Post-Deployment Review

### **After 24 Hours:**

- [ ] Review average processing times
- [ ] Check error rate trends
- [ ] Verify no rate limit errors
- [ ] Collect user feedback
- [ ] Document any issues encountered

### **After 1 Week:**

- [ ] Compare costs (old vs new)
- [ ] Analyze performance metrics
- [ ] Fine-tune if needed
- [ ] Update documentation based on learnings

---

## üìä Metrics Dashboard

**Monitor these metrics:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AI Processing Metrics                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Avg Processing Time (2749Q):  11.2s  ‚úÖ        ‚îÇ
‚îÇ Error Rate:                    0.3%   ‚úÖ        ‚îÇ
‚îÇ Rate Limit Errors:             0      ‚úÖ        ‚îÇ
‚îÇ Avg Wave Time:                 2.1s   ‚úÖ        ‚îÇ
‚îÇ RPM Usage:                     5,980  ‚úÖ        ‚îÇ
‚îÇ User Satisfaction:             98%    ‚úÖ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Status: ‚úÖ All metrics within expected ranges
```

---

## ‚úÖ Final Checklist

### **Pre-Deployment**
- [x] Configuration updated in code
- [x] Documentation complete (4 files)
- [x] Testing plan defined
- [x] Rollback plan ready
- [x] Monitoring plan established

### **During Deployment**
- [ ] Deploy code to production
- [ ] Verify logs show new configuration
- [ ] Run small test file (100Q)
- [ ] Run medium test file (500Q)
- [ ] Run large test file (2749Q)
- [ ] Monitor rate limit usage

### **Post-Deployment**
- [ ] All tests passing
- [ ] No rate limit errors
- [ ] Processing times improved
- [ ] Error rates acceptable
- [ ] User feedback positive

---

## üéâ Success!

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë        MIGRATION COMPLETE - ENJOY!                 ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                    ‚ïë
‚ïë  ‚úÖ Configuration updated                         ‚ïë
‚ïë  ‚úÖ Tests passing                                 ‚ïë
‚ïë  ‚úÖ Performance improved                          ‚ïë
‚ïë  ‚úÖ Users happy                                   ‚ïë
‚ïë                                                    ‚ïë
‚ïë  Result: 2.3x faster processing! üöÄ               ‚ïë
‚ïë                                                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

**You're now running the optimal AI configuration!** üéä

---

**Document Version**: 1.0  
**Date**: October 2, 2025  
**Status**: ‚úÖ Ready for Use
